{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install YOLOv8**"
      ],
      "metadata": {
        "id": "_dhCQeroV-tr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gje4pTYRe4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4500663d-7272-47cf-8fed-43ad6d638123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.2/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "i-0QNiYORvQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing a custom dataset**"
      ],
      "metadata": {
        "id": "-HuaIqNgWe7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xIdiX16pR3aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63909fe8-bc00-478c-c7b9-a5f6dfc84473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/dataset_cats_dogs.zip"
      ],
      "metadata": {
        "id": "ck1mhj_6R6I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d809eb63-f7d5-47f0-845f-ddb1db4c3b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/dataset_cats_dogs.zip\n",
            "   creating: dataset_cats_dogs/\n",
            "   creating: dataset_cats_dogs/cats/\n",
            "  inflating: dataset_cats_dogs/cats/cat.0.jpg  \n",
            "  inflating: dataset_cats_dogs/cats/cat.1.jpg  \n",
            "  inflating: dataset_cats_dogs/cats/cat.2.jpg  \n",
            "  inflating: dataset_cats_dogs/cats/cat.3.jpg  \n",
            "  inflating: dataset_cats_dogs/cats/cat.4.jpg  \n",
            "   creating: dataset_cats_dogs/dogs/\n",
            "  inflating: dataset_cats_dogs/dogs/dog.0.jpg  \n",
            "  inflating: dataset_cats_dogs/dogs/dog.1.jpg  \n",
            "  inflating: dataset_cats_dogs/dogs/dog.2.jpg  \n",
            "  inflating: dataset_cats_dogs/dogs/dog.3.jpg  \n",
            "  inflating: dataset_cats_dogs/dogs/dog.4.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "def split(augmentation_directory,to_path):\n",
        "    main_dir = os.listdir(augmentation_directory)\n",
        "\n",
        "    os.mkdir(os.path.join(to_path, 'train'))\n",
        "    os.mkdir(os.path.join(to_path, 'test'))\n",
        "    os.mkdir(os.path.join(to_path, 'val'))\n",
        "\n",
        "    for each_dir in main_dir:\n",
        "        os.mkdir(os.path.join(to_path, 'train', each_dir))\n",
        "        os.mkdir(os.path.join(to_path, 'test', each_dir))\n",
        "        os.mkdir(os.path.join(to_path, 'val', each_dir))\n",
        "        files = os.listdir(os.path.join(augmentation_directory, each_dir))\n",
        "\n",
        "        train_per = round(len(files) * 0.7)\n",
        "        valid_per = round(len(files) * 0.2)\n",
        "        test_per = round(len(files) * 0.1)\n",
        "\n",
        "        for every_file in files[:train_per]:\n",
        "            shutil.copyfile(os.path.join(augmentation_directory, each_dir, every_file),\n",
        "                            os.path.join(to_path, 'train', each_dir, every_file))\n",
        "        for every_file in files[train_per:train_per + valid_per]:\n",
        "            shutil.copyfile(os.path.join(augmentation_directory, each_dir, every_file),\n",
        "                            os.path.join(to_path, 'val', each_dir, every_file))\n",
        "        for every_file in files[train_per + valid_per:]:\n",
        "            shutil.copyfile(os.path.join(augmentation_directory, each_dir, every_file),\n",
        "                            os.path.join(to_path, 'test', each_dir, every_file))\n",
        "\n",
        "\n",
        "class DataAugmentation:\n",
        "    \"\"\"\n",
        "    Handles with various augmentations for dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fill(self, img, h, w):\n",
        "        img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
        "        return img\n",
        "\n",
        "    def horizontal_shift(self, img, ratio=0.0):\n",
        "        if ratio > 1 or ratio < 0:\n",
        "            print('Value should be less than 1 and greater than 0')\n",
        "            return img\n",
        "        ratio = random.uniform(-ratio, ratio)\n",
        "        h, w = img.shape[:2]\n",
        "        to_shift = w * ratio\n",
        "        if ratio > 0:\n",
        "            img = img[:, :int(w - to_shift), :]\n",
        "        if ratio < 0:\n",
        "            img = img[:, int(-1 * to_shift):, :]\n",
        "        img = self.fill(img, h, w)\n",
        "        return img\n",
        "\n",
        "    def vertical_shift(self, img, ratio=0.0):\n",
        "        if ratio > 1 or ratio < 0:\n",
        "            print('Value should be less than 1 and greater than 0')\n",
        "            return img\n",
        "        ratio = random.uniform(-ratio, ratio)\n",
        "        h, w = img.shape[:2]\n",
        "        to_shift = h * ratio\n",
        "        if ratio > 0:\n",
        "            img = img[:int(h - to_shift), :, :]\n",
        "        if ratio < 0:\n",
        "            img = img[int(-1 * to_shift):, :, :]\n",
        "        img = self.fill(img, h, w)\n",
        "        return img\n",
        "\n",
        "    def brightness(self, img, low, high):\n",
        "        value = random.uniform(low, high)\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        hsv = np.array(hsv, dtype=np.float64)\n",
        "        hsv[:, :, 1] = hsv[:, :, 1] * value\n",
        "        hsv[:, :, 1][hsv[:, :, 1] > 255] = 255\n",
        "        hsv[:, :, 2] = hsv[:, :, 2] * value\n",
        "        hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n",
        "        hsv = np.array(hsv, dtype=np.uint8)\n",
        "        img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "        return img\n",
        "\n",
        "    def channel_shift(self, img, value):\n",
        "        value = int(random.uniform(-value, value))\n",
        "        img = img + value\n",
        "        img[:, :, :][img[:, :, :] > 255] = 255\n",
        "        img[:, :, :][img[:, :, :] < 0] = 0\n",
        "        img = img.astype(np.uint8)\n",
        "        return img\n",
        "\n",
        "    def zoom(self, img, value):\n",
        "        if value > 1 or value < 0:\n",
        "            print('Value for zoom should be less than 1 and greater than 0')\n",
        "            return img\n",
        "        value = random.uniform(value, 1)\n",
        "        h, w = img.shape[:2]\n",
        "        h_taken = int(value * h)\n",
        "        w_taken = int(value * w)\n",
        "        h_start = random.randint(0, h - h_taken)\n",
        "        w_start = random.randint(0, w - w_taken)\n",
        "        img = img[h_start:h_start + h_taken, w_start:w_start + w_taken, :]\n",
        "        img = self.fill(img, h, w)\n",
        "        return img\n",
        "\n",
        "    def horizontal_flip(self, img, flag):\n",
        "        if flag:\n",
        "            return cv2.flip(img, 1)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    def vertical_flip(self, img, flag):\n",
        "        if flag:\n",
        "            return cv2.flip(img, 0)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    def rotation(self, img, angle):\n",
        "        angle = int(random.uniform(-angle, angle))\n",
        "        h, w = img.shape[:2]\n",
        "        M = cv2.getRotationMatrix2D((int(w / 2), int(h / 2)), angle, 1)\n",
        "        img = cv2.warpAffine(img, M, (w, h))\n",
        "        return img\n",
        "\n",
        "\n",
        "    def process(self, dataset_directory, post_process_directory, cl):\n",
        "        if not os.path.exists(os.path.join(post_process_directory, cl)):\n",
        "            os.mkdir(os.path.join(post_process_directory, cl))\n",
        "\n",
        "        for each_file in os.listdir(os.path.join(dataset_directory, cl)):\n",
        "            filename, file_extension = os.path.splitext(each_file)\n",
        "\n",
        "            if file_extension in ['.jpg', '.jpeg', '.png']:\n",
        "                image = cv2.imread(os.path.join(dataset_directory, cl, each_file))\n",
        "                multi_images = (\n",
        "                    self.horizontal_shift(image), self.vertical_shift(image), self.brightness(image, 0.5, 3),\n",
        "                    self.zoom(image, 0.5), self.channel_shift(image, 60), self.horizontal_flip(image, True),\n",
        "                    self.vertical_flip(image, True), self.rotation(image, 60))\n",
        "\n",
        "                _file_name = 0\n",
        "                for each_element in multi_images:\n",
        "                    image = each_element\n",
        "                    cv2.imwrite(\n",
        "                        os.path.join(post_process_directory, cl, f\"{each_file[:-4]}\" + \"_\" + f\"{_file_name}\" + \".jpg\"),\n",
        "                        image)\n",
        "                    _file_name += 1\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    dataset_directory = Path(r\"/content/dataset_cats_dogs\")\n",
        "    augmentation_directory = '/content/augmented_dataset'\n",
        "    os.mkdir(augmentation_directory)\n",
        "    target_directory=\"/content/split_dataset\"\n",
        "    os.mkdir(target_directory)\n",
        "    cls = ['cats', 'dogs']\n",
        "\n",
        "    augmentation_obj = DataAugmentation()\n",
        "    for cl in cls:\n",
        "        augmentation_obj.process(dataset_directory, augmentation_directory, cl)\n",
        "\n",
        "    for cl in cls:\n",
        "        if not os.path.exists(os.path.join(augmentation_directory, cl)):\n",
        "            os.mkdir(os.path.join(augmentation_directory, cl))\n",
        "\n",
        "    split(augmentation_directory,target_directory)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Uyb7B1-lR7Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Training**"
      ],
      "metadata": {
        "id": "x0SvIEegWTVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=classify mode=train model=yolov8n-cls.pt data=/content/split_dataset epochs=10 imgsz=128"
      ],
      "metadata": {
        "id": "K3FPORBFTHzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960f416f-795f-49b5-9615-698f6c296490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n",
            "100% 5.28M/5.28M [00:00<00:00, 61.8MB/s]\n",
            "Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/split_dataset, epochs=1, patience=50, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/split_dataset/train... found 56 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/split_dataset/val... found 16 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/split_dataset/test... found 8 images in 2 classes âœ… \n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1440850 parameters, 1440850 gradients\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train... 56 images, 0 corrupt: 100% 56/56 [00:00<00:00, 1976.56it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/split_dataset/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=128, width=128, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/val... 16 images, 0 corrupt: 100% 16/16 [00:00<00:00, 5784.25it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/split_dataset/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 128 train, 128 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "        1/1         0G     0.2163         16        128:  25% 1/4 [00:00<00:02,  1.35it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "        1/1         0G      0.208         16        128:  50% 2/4 [00:01<00:01,  1.37it/s]\n",
            "100% 755k/755k [00:00<00:00, 14.3MB/s]\n",
            "        1/1         0G      0.193          8        128: 100% 4/4 [00:02<00:00,  1.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00,  4.77it/s]\n",
            "                   all      0.438          1\n",
            "\n",
            "1 epochs completed in 0.002 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1437442 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/split_dataset/train... found 56 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/split_dataset/val... found 16 images in 2 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/split_dataset/test... found 8 images in 2 classes âœ… \n",
            "               classes   top1_acc   top5_acc: 100% 1/1 [00:00<00:00,  7.63it/s]\n",
            "                   all      0.438          1\n",
            "Speed: 0.0ms preprocess, 4.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/runs/classify/train/results.csv | head -10"
      ],
      "metadata": {
        "id": "4-CSnWxNTXF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec45d5cd-5814-4b57-a6b8-d446fed56377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2\n",
            "                      1,                0.19301,                 0.4375,                      1,                0.19167,              2.142e-05,              2.142e-05,              2.142e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference with Custom Model**"
      ],
      "metadata": {
        "id": "X61wUf8JWvpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=classify mode=predict model=/content/runs/classify/train/weights/best.pt conf=0.25 source=/content/split_dataset/test/dogs/dog.0_0.jpg"
      ],
      "metadata": {
        "id": "hMGDx43NTpWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6a86fb-74bf-4817-fa46-c7c74b6e256b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1437442 parameters, 0 gradients\n",
            "\n",
            "image 1/1 /content/split_dataset/test/dogs/dog.0_0.jpg: 128x128 dogs 0.65, cats 0.35, 42.3ms\n",
            "Speed: 3.4ms preprocess, 42.3ms inference, 0.2ms postprocess per image at shape (1, 3, 128, 128)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    }
  ]
}